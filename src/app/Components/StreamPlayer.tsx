import { useEffect, useRef, useState } from "react";

const WebMStreamPlayer = () => {
    const videoRef = useRef<HTMLVideoElement>(null);
    const mediaSourceRef = useRef<MediaSource | null>(null);
    const sourceBufferRef = useRef<SourceBuffer | null>(null);
    const [connected, setConnected] = useState(false);
    const [fps, setFps] = useState(0);
    const frameCount = useRef(0);
    const queue: Uint8Array[] = [];
    const [thumbnail, setThumbnail] = useState<string | null>(null); // Ajout de l'√©tat pour l'image de pr√©visualisation

    useEffect(() => {
        if (!window.MediaSource || !videoRef.current) {
            console.error("MediaSource non support√© ou vid√©o non trouv√©e");
            return;
        }

        const mediaSource = new MediaSource();
        videoRef.current.src = URL.createObjectURL(mediaSource);
        mediaSourceRef.current = mediaSource;

        // Fonction pour cr√©er un nouveau SourceBuffer
        const createSourceBuffer = () => {
            const mime = 'video/webm; codecs="vp8, vorbis"';
            if (!MediaSource.isTypeSupported(mime)) {
                console.error("Type non support√©:", mime);
                return;
            }

            const sourceBuffer = mediaSource.addSourceBuffer(mime);
            sourceBufferRef.current = sourceBuffer;

            sourceBuffer.addEventListener("updateend", () => {
                if (queue.length && !sourceBuffer.updating) {
                    const next = queue.shift();
                    if (next) {
                        try {
                            console.log(
                                "[VIDEO] üéûÔ∏è appendBuffer direct",
                                next.length,
                                "octets"
                            );
                            if (
                                sourceBuffer &&
                                mediaSource.readyState === "open" &&
                                !sourceBuffer.updating
                            ) {
                                sourceBuffer.appendBuffer(next);
                            } else {
                                console.error(
                                    "[VIDEO] ‚ùå Le SourceBuffer ou le MediaSource n'est plus valide."
                                );
                            }
                        } catch (err) {
                            console.error(
                                "[VIDEO] ‚ùå appendBuffer √©chou√©:",
                                err
                            );
                        }
                    }
                }
            });
        };

        mediaSource.addEventListener("sourceopen", () => {
            createSourceBuffer();

            const ws = new WebSocket("ws://localhost:4000");
            ws.binaryType = "arraybuffer";

            ws.onopen = () => {
                console.log("[WS] ‚úÖ Connect√©");
                setConnected(true);
            };

            ws.onclose = () => {
                console.log("[WS] ‚ùå D√©connect√©");
                setConnected(false);
            };

            ws.onmessage = (event) => {
                const buffer = event.data as ArrayBuffer;
                const view = new DataView(buffer);

                const ts = view.getBigUint64(0, true);
                const videoData = new Uint8Array(buffer.slice(8)); // Suppose 8 bytes pour timestamp

                console.log(
                    "[VIDEO] üé¨ Donn√©es vid√©o re√ßues:",
                    videoData.length
                );

                // V√©rification de la validit√© du flux vid√©o avant l'ajout
                if (sourceBufferRef.current?.updating || queue.length > 0) {
                    queue.push(videoData); // Si le buffer est en train de traiter des donn√©es, on les met dans la file d'attente
                } else {
                    try {
                        console.log(
                            "[VIDEO] üéûÔ∏è appendBuffer direct (",
                            videoData.length,
                            "octets)"
                        );
                        if (
                            sourceBufferRef.current &&
                            mediaSource.readyState === "open" &&
                            !sourceBufferRef.current.updating
                        ) {
                            sourceBufferRef.current.appendBuffer(videoData);
                        } else {
                            console.error(
                                "[VIDEO] ‚ùå Le SourceBuffer ou le MediaSource n'est plus valide."
                            );
                        }
                    } catch (err) {
                        console.error("[VIDEO] ‚ùå appendBuffer √©chou√©:", err);
                    }

                    // Si les donn√©es contiennent un segment d'image, tu peux l'extraire pour afficher la preview
                    if (!thumbnail) {
                        const blob = new Blob([videoData], {
                            type: "image/webp",
                        });
                        const url = URL.createObjectURL(blob);
                        setThumbnail(url); // Mettre √† jour l'image de pr√©visualisation
                    }
                }

                frameCount.current++;
            };

            const interval = setInterval(() => {
                setFps(frameCount.current);
                frameCount.current = 0;
            }, 1000);

            return () => {
                ws.close();
                clearInterval(interval);

                // Avant de fermer, v√©rifier l'√©tat de MediaSource
                const mediaSource = mediaSourceRef.current;
                if (mediaSource && mediaSource.readyState === "open") {
                    try {
                        console.log(
                            "[VIDEO] Tentative de fermeture du MediaSource."
                        );
                        mediaSource.endOfStream();
                    } catch (err) {
                        console.error(
                            "[VIDEO] ‚ùå √âchec de la fermeture du MediaSource:",
                            err
                        );
                    }
                }
            };
        });

        return () => {
            // Lors du d√©montage, v√©rifier l'√©tat avant de fermer
            const mediaSource = mediaSourceRef.current;
            if (mediaSource && mediaSource.readyState === "open") {
                try {
                    console.log(
                        "[VIDEO] Tentative de fermeture du MediaSource (d√©montage)."
                    );
                    mediaSource.endOfStream();
                } catch (err) {
                    console.error(
                        "[VIDEO] ‚ùå √âchec de la fermeture du MediaSource (d√©montage):",
                        err
                    );
                }
            }
        };
    }, [thumbnail]);

    return (
        <div style={{ padding: "1rem", maxWidth: 640, margin: "0 auto" }}>
            <div style={{ marginBottom: "1rem" }}>
                <p>
                    <strong>Status :</strong>{" "}
                    {connected ? "‚úÖ Connect√©" : "‚ùå D√©connect√©"}
                </p>
                <p>
                    <strong>FPS :</strong> {fps}
                </p>
            </div>

            {/* Affichage de l'image de pr√©visualisation avant la vid√©o */}
            {thumbnail ? (
                <img src={thumbnail} alt="Preview" style={{ width: "100%" }} />
            ) : (
                <video
                    ref={videoRef}
                    controls
                    autoPlay
                    muted
                    playsInline
                    style={{ width: "100%", backgroundColor: "black" }}
                />
            )}
        </div>
    );
};

export default WebMStreamPlayer;
